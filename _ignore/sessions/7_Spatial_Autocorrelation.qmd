---
title: "Spatial Autocorrelation"
subtitle: "GESIS Workshop: Introduction to Geospatial Techniques for Social Scientists in R"
author: "Stefan Jünger & Dennis Abel"
date: April 10, 2025
execute:
  echo: true
format:
  revealjs:
    embed-resources: true
    theme: [simple, tweaks.css]
    smaller: true
    scrollable: true
    slide-number: "c/t"
    logo: ../img/GESIS-Logo_2024.svg.png
    fig-align: center
editor_options: 
  chunk_output_type: console
---

```{r}
#| include: false
library(dplyr)
library(ggplot2)
library(sf)
library(terra)
library(tmap)
```

## Now

```{r}
#| echo: false
source("course_content.R") 

course_content |> 
  kableExtra::row_spec(12, background = "yellow")
```

## Thus far

We've done some wrangling, mapping, and linking of geospatial data (with georeferenced survey data)

We've seen that geospatial data are relevant to provide context (as social scientists, we know that space is important), and they are nice to look at--we can tell a story!

**However, geospatial data can be interesting on their own for social science studies!**

## Tobler's first law of geography

> [E]verything is related to everything else, but near things are more related than distant things (Tobler 1970, p. 236)^[Tobler, W. R. (1970). A Computer Movie Simulating Urban Growth in the Detroit Region. Economic Geography, 46, 234–240. https://doi.org/10.2307/143141]

This means nearby geographical regions, institutions, or people are more similar or have a stronger influence on each other.

**What we get is an interdependent system.**

## Spatial Interdependence or Autocorrelation

Tobler's law is the fundamental principle of doing spatial analysis. We want to know

1. If observations in our data are spatially interdependent
2. And how this interdependence can be explained (= data generation process)

## Developing a model of connectiveness: the chess board

:::: columns
::: {.column width="50%"}
![](../img/random.png){fig-align="center" width="75%"}
:::

::: {.column width="50%"}
![](../img/non_random.png){fig-align="center" width="75%"}

:::
::::

## Rook and queen neighborhoods

:::: columns
::: {.column width="50%"}
![](../img/rook.png){fig-align="center" width="75%"}
:::

::: {.column width="50%"}
![](../img/queen.png){fig-align="center" width="75%"}
:::
::::

## It's an interdependent system

:::: columns
::: {.column width="50%"}
![](../img/rook_interdependent.png){fig-align="center" width="75%"}
:::

::: {.column width="50%"}
![](../img/queen_interdependent.png){fig-align="center" width="75%"}
:::
::::

## Let's do it hands-on: Our 'research' question

Say we are interested in AfD voting outcomes in relation to ethnic compositions of neighborhoods.

- Combination of far-right voting research with Allport's classic contact theory
- We are just doing it in the Urban context of Cologne (again)

## Voting districts

```{r}
#| eval: false
voting_districts <-
  sf::st_read("./data/Stimmbezirk.shp") |> 
  dplyr::transmute(Stimmbezirk = as.numeric(nummer))

head(voting_districts, 2)
```

```{r}
#| echo: false
voting_districts <-
  sf::st_read("../../data/Stimmbezirk.shp") |> 
  dplyr::transmute(Stimmbezirk = as.numeric(nummer))

head(voting_districts, 2)
```

## AfD vote share

```{r}
afd_votes <-
  glue::glue(
    "https://www.stadt-koeln.de/wahlen/bundestagswahl/09-2021/praesentation/\\
    Open-Data-Bundestagswahl476.csv"
  ) |> 
  readr::read_csv2() |>
  dplyr::transmute(Stimmbezirk = `gebiet-nr`, afd_share = (F1 / F) * 100)

head(afd_votes, 2)
```

## Simple ID matching to link data

```{r}
election_results <-
  dplyr::left_join(
    voting_districts,
    afd_votes,
    by = "Stimmbezirk"
  )

head(election_results, 2)
```

## Do vote shares spatially cluster?

:::: columns
::: {.column width="50%"}
```{r}
#| eval: false
#| fig.asp: 1
ggplot() +
  geom_sf(
    data = election_results,
    aes(fill = afd_share)
    ) +
  scale_fill_viridis_c()
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig.asp: 1
ggplot() +
  geom_sf(
    data = election_results,
    aes(fill = afd_share)
    ) +
  scale_fill_viridis_c()
```
:::
::::

## Pull in German Census data

```{r}
#| eval: false
immigrants_cologne <- terra::rast("./data/immigrants_cologne.tif")

inhabitants_cologne <- terra::rast("./data/inhabitants_cologne.tif")

immigrant_share_cologne <-
  (immigrants_cologne / inhabitants_cologne) * 100
```

```{r}
#| echo: false
immigrants_cologne <- terra::rast("../../data/immigrants_cologne.tif")

inhabitants_cologne <- terra::rast("../../data/inhabitants_cologne.tif")

immigrant_share_cologne <-
  (immigrants_cologne / inhabitants_cologne) * 100
```

## It's raster data

:::: columns
::: {.column width="50%"}
```{r}
#| eval: false
#| fig.asp: 1
ggplot() +
  tidyterra::geom_spatraster(
    data = immigrant_share_cologne,
    aes(fill = immigrants_cologne)
    ) +
  scale_fill_viridis_c()
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig.asp: 1
ggplot() +
  tidyterra::geom_spatraster(
    data = immigrant_share_cologne,
    aes(fill = immigrants_cologne)
    ) +
  scale_fill_viridis_c()
```
:::
::::

## Linking: Let's get geographical

As the voting (vector) data differs from the Census raster data, we cannot use simple ID matching like before.

- We have to rely on spatial linking techniques
- We could use `terra::extract()`
  - But as a default, it only captures raster cells as a whole and not their spatial fraction
  - Which is honestly okay for most applications
  - But why not try something else?

---

## <small>`exactextractr::exact_extract()`!</small>

```{r}
election_results <-
  election_results |>
  dplyr::mutate(
    immigrant_share = 
      exactextractr::exact_extract(
        immigrant_share_cologne, election_results, 'mean', progress = FALSE
      ),
    inhabitants = 
      exactextractr::exact_extract(
        inhabitants_cologne, election_results, 'mean', progress = FALSE
      )
  )

head(election_results, 2)
```

## Voilà

:::: columns
::: {.column width="50%"}
```{r}
#| eval: false
#| fig.asp: 1
ggplot() +
  geom_sf(
    data = election_results,
    aes(fill = immigrant_share)
    ) +
  scale_fill_viridis_c()
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig.asp: 1
ggplot() +
  geom_sf(
    data = election_results,
    aes(fill = immigrant_share)
    ) +
  scale_fill_viridis_c()
```
:::
::::


## How to test spatial autocorrelation

:::: columns
::: {.column width="50%"}
We now have to ask

- Do the spatial units relate to each other?
- If yes, in which way?
  - Only if they are bordering each other? (i.e., Queens or Rooks)
  - Or also if they are in proximity but not necessarily contiguous?
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig.asp: 1
ggplot() +
  geom_sf(
    data = election_results
    )
```
:::
::::

## Let's try Queens neighborhoods

```{r}
queens_neighborhoods <-
  spdep::poly2nb(
    election_results,
    queen = TRUE
  )

summary(queens_neighborhoods)
```

## Connected regions

:::: columns
::: {.column width="50%"}
```{r}
#| eval: false
#| fig.asp: 1
queens_neighborhoods |>
  spdep::nb2lines(
    coords = sf::st_as_sfc(election_results), 
    as_sf = TRUE
  ) |>
  tm_shape() +
  tm_dots() +
  tm_lines()
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig.asp: 1
queens_neighborhoods |>
  spdep::nb2lines(
    coords = sf::st_as_sfc(election_results), 
    as_sf = TRUE
  ) |>
  tm_shape() +
  tm_dots() +
  tm_lines()
```
:::
::::

## Can we now start?

Unfortunately, we are not yet done with creating the links between neighborhoods. What we receive is, in principle, a huge matrix with connected observations.

```{r}
#| echo: false
spdep::nb2mat(queens_neighborhoods, style = "B")[1:10, 1:10]
```

That's nothing we could plug into a statistical model, such as a regression or the like (see next session).

## Normalization

Normalization is the process of creating actual spatial weights. There is a huge dispute on how to do it (Neumayer & Plümper, 2016)^[Neumayer, E., & Plümper, T. (2016). W. Political Science Research and Methods, 4(01), 175–193. https://doi.org/10.1017/psrm.2014.40]. But nobody questions whether it should be done in the first place since, among others, it restricts the parameter space of the weights.

:::: columns
::: {.column width="50%"}
```{r}
#| echo: false
#| fig.asp: 1
spdep::nb2mat(queens_neighborhoods, style = "B")[1:5, 1:5]

rowSums(spdep::nb2mat(queens_neighborhoods, style = "B")[1:5, 1:5]) |> as.vector()
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig.asp: 1
spdep::nb2mat(queens_neighborhoods, style = "W")[1:5, 1:5]

rowSums(spdep::nb2mat(queens_neighborhoods, style = "W")[1:5, 1:5]) |> as.vector()
```
:::
::::

## Row-normalization

One of the disputed but, at the same time, standard procedures is row-normalization. It divides all individual weights (=connections between spatial units) $w_{ij}$ by the row-wise sum of of all other weights:

$$W = \sum_j\frac{w_{ij}}{\sum_jw_{ij}}$$

An alternative would be minmax-normalization:

$$W = \sum_j\frac{w_{ij} - min(w_{ij})}{max(w_{ij})-min(w_{ij})}$$

## Apply row-normalization

```{r}
queens_W <- spdep::nb2listw(queens_neighborhoods, style = "W")

summary(queens_W)
```

## Test of spatial autocorrelation: Moran's I

$$I=\frac{N}{\sum_{i=1}^N\sum_{j=1}^Nw_{ij}}\frac{\sum_{i=1}^{N}\sum_{j=1}^Nw_{ij}(x_i-\bar{x})(x_j-\bar{x})}{\sum_{i=1}^N(x_i-\bar{x})^2}$$

Most and foremost, Moran's I use the previously created weights between all spatial unit pairs $w_{ij}$. It weights deviations from an overall mean value of connected pairs according to the strength of the modeled spatial relations. Moran's I can be interpreted as a correlation coefficient (-1 = perfect negative spatial autocorrelation; +1 = perfect positive spatial autocorrelation).

## Moran's I in `spdep`

```{r}
spdep::moran.test(
  election_results$immigrant_share, 
  listw = queens_W
)
```

## Test of spatial autocorrelation: Geary's C

Moran's I is a global statistic for spatial autocorrelation. It can produce issues when there are only local clusters of spatial interdependence in the data. An alternative is the use of `Geary's C`:

$$C=\frac{(N-1)\sum_i\sum_jw_{ij}(x_i-x_j)^2}{2\sum_{i=1}^N\sum_{j=1}^Nw_{ij}\sum_i(x_i-\bar{x})^2}$$

As you can see, in the numerator, the average value $\bar{x}$ is not as prominent as in Moran's I. Geary's C only produces values between 0 and 2 (value near 0 = positive spatial autocorrelation; 1 = no spatial autocorrelation; values near 2 = negative spatial autocorrelation).

## Geary's C in `spdep`

```{r}
spdep::geary.test(
  election_results$immigrant_share, 
  listw = queens_W
)
```

## Modern inferface: `sfdep` package

The [`sfdep`](https://cran.r-project.org/web/packages/sfdep/index.html) package provides a more `tidyverse`-compliant syntax to spatial weights. See:

```{r}
election_results <-
  election_results |> 
  dplyr::mutate(
    neighbors = sfdep::st_contiguity(election_results), # queen neighborhoods by default
    weights = sfdep::st_weights(neighbors)
  )

head(election_results, 2)
```

## Calculating once again Moran's I

```{r}
library(magrittr)

election_results %$% 
  sfdep::global_moran_test(immigrant_share, neighbors, weights)
```

## Calculating once again Geary's C

```{r}
election_results %$% 
  sfdep::global_c_test(immigrant_share, neighbors, weights)
```


## Exercise 7: Neighborhood Matrices

[Exercise](https://stefanjuenger.github.io/gesis-workshop-geospatial-techniques-R-2025/exercises/7_Neighborhood_Matrices.html)


## Measures of local spatial autocorrelation: LISA clusters

We show you the `sfdep` package because it provides nice functions to calculate *local* measures of spatial autocorrelation. One popular choice is the estimation of Local Indicators of Spatial Autocorrelation (i.e., LISA clusters). Most straightforwardly, they can be interpreted as case-specific indicators of spatial autocorrelation:

$$I_i=\frac{x_i-\bar{x}}{\frac{\sum_{i-1}^N(x_i-\bar{x})^2}{N}}\sum_{j=1}^Nw_{ij}(x_j-\bar{x})$$

## Local Moran's I in `sfdep`

```{r}
lisa <- 
  election_results |> 
  dplyr::mutate(
    lisa = sfdep::local_moran(afd_share, neighbors, weights)
  ) |>
  tidyr::unnest()

head(lisa, 2)
```

## It's also nice for mapping

:::: columns
::: {.column width="50%"}
```{r}
#| eval: false
#| fig.asp: 1
ggplot() +
  geom_sf(
    data = lisa,
    aes(fill = ii)
  ) +
  scale_fill_viridis_c()
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig.asp: 1
ggplot() +
  geom_sf(
    data = lisa,
    aes(fill = ii)
  ) +
  scale_fill_viridis_c()
```
:::
::::

## One last bit: bivariate local Moran's I

:::: columns
::: {.column width="50%"}
```{r}
#| eval: false
#| fig.asp: 1
lisa_bivariate <- 
  election_results |> 
  dplyr::mutate(
    lisa = sfdep::local_moran_bv(
      afd_share, 
      immigrant_share, 
      neighbors, 
      weights
      )
  ) |> 
  tidyr::unnest()

ggplot() +
  geom_sf(
    data = lisa_bivariate,
    aes(fill = Ib)
  ) +
  scale_fill_viridis_c()
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig.asp: 1
lisa_bivariate <- 
  election_results |> 
  dplyr::mutate(
    lisa = sfdep::local_moran_bv(
      afd_share, 
      immigrant_share, 
      neighbors, 
      weights
      )
  ) |> 
  tidyr::unnest()

ggplot() +
  geom_sf(
    data = lisa_bivariate,
    aes(fill = Ib)
  ) +
  scale_fill_viridis_c()
```
:::
::::

## Wrap up

You now know how to model the connectedness of spatial units, investigate spatial autocorrelation globally and locally, and map it. 
  
There's way more, particularly regarding spatial weights (see exercise), clustering techniques (e.g., Hot Spot Analysis), or autocorrelation with more than one or two variables.

**Nevertheless, now we know our data are spatially autocorrelated. Let's try to find out why this is the case via some spatial econometrics**
